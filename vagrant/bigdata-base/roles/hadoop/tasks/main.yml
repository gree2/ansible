---
# tasks file for hadoop

- name: create user hadoop
  user: >
    name={{ user.hadoop }}
    password={{ user.hadoop_password }}
    generate_ssh_key=yes
    ssh_key_bits=2048
    ssh_key_file=.ssh/id_rsa

- name: ensure the /home/hadoop/.ssh directory exists
  file: >
    path=/home/{{ user.hadoop }}/.ssh
    state=directory

- name: add to authorized_keys
  shell: "cat /home/{{ user.hadoop }}/.ssh/id_rsa.pub >> /home/{{ user.hadoop }}/.ssh/authorized_keys"
  become: yes
  become_user: "{{ user.hadoop }}"

- name: add to known_hosts
  shell: "ssh-keyscan -H {{ item }} >> /home/{{ user.hadoop }}/.ssh/known_hosts"
  become: yes
  become_user: "{{ user.hadoop }}"
  with_items:
    - "0.0.0.0"
    - "192.168.100.100"
    - "singlenode"

- name: create /app/hadoop
  file: >
    path={{ dir.app_base }}
    state=directory
    owner={{ user.hadoop }}
    group={{ user.hadoop_group }}
    recurse=yes

- name: create /opt/bigdata
  file: >
    path={{ dir.install_base }}
    state=directory
    owner={{ user.hadoop }}
    group={{ user.hadoop_group }}
    recurse=yes

- name: unzip hadoop tar ball
  unarchive: >
    src=/software/{{ version.hadoop }}.tar.gz
    dest={{ dir.install_base }}
    copy=no
    owner={{ user.hadoop }}
    group={{ user.hadoop_group }}

- name: hadoop symbolic link
  file: >
    src={{ dir.install_base }}/{{ version.hadoop }}
    dest={{ dir.install_base }}/hadoop
    state=link
    owner={{ user.hadoop }}
    group={{ user.hadoop_group }}

- name: hadoop conf
  template: >
    src={{ item }}.j2
    dest={{ dir.hadoop_conf }}/{{ item }}
    owner={{ user.hadoop }}
    group={{ user.hadoop_group }}
  with_items:
    - core-site.xml
    - hadoop-env.sh
    - hdfs-site.xml
    - mapred-site.xml
    - slaves
    - yarn-site.xml

- name: copy .bashrc
  copy: >
    src=.bashrc
    dest=/home/{{ user.hadoop }}/.bashrc
    owner={{ user.hadoop }}
    group={{ user.hadoop_group }}

- name: source .bashrc
  shell: . /home/{{ user.hadoop }}/.bashrc
  become: yes
  become_user: "{{ user.hadoop }}"

- name: hadoop namenode format
  shell: "{{ dir.hadoop }}/bin/hdfs namenode -format -force"
  become: yes
  become_user: "{{ user.hadoop }}"

- name: hadoop start nn dn snn daemon
  shell: "{{ dir.hadoop }}/sbin/start-dfs.sh"
  become: yes
  become_user: "{{ user.hadoop }}"

- name: jps
  shell: /usr/bin/jps
  become: yes
  become_user: "{{ user.hadoop }}"

# - name: hdfs dfs -ls /
#   shell: "{{ dir.hadoop }}/bin/hdfs dfs -ls /"
#   become: yes
#   become_user: "{{ user.hadoop }}"
